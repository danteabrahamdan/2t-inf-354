{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segundo turno\n",
    "\n",
    "Dado el conjunto CPU en weka (formato arff), transforme la misma a formato CSV y la lectura desde python\n",
    "\n",
    "![\"./cpu0.png\"](./cpu0.png)\n",
    "\n",
    "Guardamos en formato CSV\n",
    "\n",
    "![./cpu.png](./cpu.png)\n",
    "\n",
    "Realizamos la lectura del archico cpu.with.vendor.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de archivo \"cpu.with.vendor.csv\" desde python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor</th>\n",
       "      <th>MYCT</th>\n",
       "      <th>MMIN</th>\n",
       "      <th>MMAX</th>\n",
       "      <th>CACH</th>\n",
       "      <th>CHMIN</th>\n",
       "      <th>CHMAX</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adviser</td>\n",
       "      <td>125</td>\n",
       "      <td>256</td>\n",
       "      <td>6000</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vendor  MYCT  MMIN   MMAX  CACH  CHMIN  CHMAX  class\n",
       "0  adviser   125   256   6000   256     16    128    199\n",
       "1   amdahl    29  8000  32000    32      8     32    253\n",
       "2   amdahl    29  8000  32000    32      8     32    253\n",
       "3   amdahl    29  8000  32000    32      8     32    253\n",
       "4   amdahl    29  8000  16000    32      8     16    132"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./cpu.with.vendor.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "### Valores faltantes\n",
    "\n",
    "Antes de comenzar a manejar los valores perdidos, es importante identificar los valores perdidos y saber con qué valor se reemplazan. Para el caso del dataset CPU, no existen valores faltantes ya que ninguna columna, presenta valores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209 entries, 0 to 208\n",
      "Data columns (total 8 columns):\n",
      "vendor    209 non-null object\n",
      "MYCT      209 non-null int64\n",
      "MMIN      209 non-null int64\n",
      "MMAX      209 non-null int64\n",
      "CACH      209 non-null int64\n",
      "CHMIN     209 non-null int64\n",
      "CHMAX     209 non-null int64\n",
      "class     209 non-null int64\n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 13.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División del conjunto de datos\n",
    "\n",
    "Definimos a las 1ras 6 columnas como variables independientes y a la ultima como variable dependiente, es la que se usará para hacer la predicción.\n",
    "Entonces, creamos la matriz de caracteristicas y el vector de la variable dependiente\n",
    "\n",
    "* Matriz de caracteristicas: columnas 0 a la 6\n",
    "* Vector de la variable dependiente, columna 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:7].values\n",
    "y = dataset.iloc[:, 7].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caracteristicas categoricas\n",
    "\n",
    "la biblioteca de aprendizaje automático de `sklearn` no admite el manejo de datos categóricos. Incluso para los modelos basados en árboles, es necesario convertir características categóricas en una representación numérica.\n",
    "\n",
    "Veamos si existen columnas categoricas en el dataset.\n",
    "\n",
    "al tener variables categoricas dentro del conjunto de datos. Se trata de traducir todo a valores numericos codificando de la forma en la que haga falta. Esto con `LabelEncoder` propia de la libreria de `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vendor    object\n",
       "MYCT       int64\n",
       "MMIN       int64\n",
       "MMAX       int64\n",
       "CACH       int64\n",
       "CHMIN      int64\n",
       "CHMAX      int64\n",
       "class      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 125, 256, ..., 256, 16, 128],\n",
       "       [1, 29, 8000, ..., 32, 8, 32],\n",
       "       [1, 29, 8000, ..., 32, 8, 32],\n",
       "       ...,\n",
       "       [28, 125, 2000, ..., 0, 2, 14],\n",
       "       [29, 480, 512, ..., 32, 0, 0],\n",
       "       [29, 480, 1000, ..., 0, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un labelenconder para cada variable categorica\n",
    "labelencoder_X1 = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X1.fit_transform(X[:, 0])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dvisión en conjunto de entrenamiento y pruebas\n",
    "\n",
    "Creamos el conjunto de entrenamiento y de pruebas, eso mediante el modelo de selección de ``Scikit-learn` dividiendo el conjunto en entrenamiento 80% y pruebas 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización\n",
    "\n",
    "Escalado de variables, esto debido a que existen variables que destacan mucho (tenemos variables que estan entre un rango menor, otras que llegan a tener valores que llegan a valores de 64000), cada uno esta en una escala diferente, esto para un mejor calculo y hacemos que ninguna variable domine sobre el resto\n",
    "\n",
    "Entonces ahora estaran estandarizadas X_train, X_test, debidamente normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13686133,  1.47102315, -0.53054729, ..., -0.63206819,\n",
       "        -0.51650809, -0.64011436],\n",
       "       [ 0.6715009 , -0.47129246, -0.20866821, ...,  0.16457625,\n",
       "        -0.51650809, -0.4619492 ],\n",
       "       [-2.00169696, -0.71217018,  1.35892472, ...,  0.16457625,\n",
       "         0.43735914, -0.10561887],\n",
       "       ...,\n",
       "       [ 0.13686133,  0.03722718, -0.4699337 , ..., -0.58227791,\n",
       "        -0.2439746 , -0.4619492 ],\n",
       "       [-0.93241782,  2.27394889, -0.4699337 , ..., -0.63206819,\n",
       "        -0.51650809, -0.64011436],\n",
       "       [ 0.93882069, -0.05835922, -0.20866821, ...,  0.96122068,\n",
       "        -0.51650809, -0.49758223]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genere un árbol C4.5 en Excel y con python, explicado paso a paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportamos el dataset ya preprocesado a un archivo csv, de salida para poder trabajar con el en excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('cpu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realice una red neuronal XOR mediante python simple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero generamos la matriz de caracteristicas, en este caso debe ser una matriz binaria de la forma:\n",
    "\n",
    "| A | B |\n",
    "|---|---|\n",
    "| 0 | 0 |\n",
    "| 0 | 1 |\n",
    "| 1 | 0 |\n",
    "| 1 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "INPUT_X = np.array([\n",
    "  [0,0],\n",
    "  [0,1],\n",
    "  [1,0],\n",
    "  [1,1]\n",
    "])\n",
    "print(INPUT_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego definimos el vector de variables dependientes\n",
    "\n",
    "| XOR |\n",
    "|---|\n",
    "| 0 |\n",
    "| 1 |\n",
    "| 1 |\n",
    "| 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "RESULT = np.array([[0,1,1,0]]).T\n",
    "print(RESULT)\n",
    "\n",
    "# la tabla de verdad de la operación XOR\n",
    "print(np.append(INPUT_X,EXPECTED_RESULT, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que la red neuronal aprenda, debe calcular su prediccion, calcular el error, correguir los pesos y volver a calcular. Se tiene para el ejemplo 2 entradas y 1 salida, lo se se quiere conseguir es encontrar una conexión entre cada entrada y salida. Para esto cada entrada debe tener un peso. Esto para modificar mas o menos el peso segun su salida.\n",
    "\n",
    "Definimos la función de activación, que nos permitira modelar problemas no lineales, este mapeara cualquier valor a valores entre 0 y 1, tambien dado el caso devolveremos la derivada de la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, deriv=False):\n",
    "    if deriv:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una capa intermedia, la cual tendra el objetivo de ir aprendiendo, donde tenemos 2 entradas y 1 salida. a su vez creamos la matriz para la capa intemedia y la de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09762701  0.43037873  0.20552675]\n",
      " [ 0.08976637 -0.1526904   0.29178823]]\n",
      "[[-0.12482558]\n",
      " [ 0.783546  ]\n",
      " [ 0.92732552]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    " \n",
    "# Ahora creamos una matriz de 2x3 para las conexiones de la CAPA0 a CAPA1\n",
    "SYN0 = 2*np.random.random((2,3)) - 1\n",
    "## Y las conexiones de la CAPA1 a la CAPA2 que es la salida\n",
    "SYN1 = 2*np.random.random((3,1)) - 1\n",
    "print(SYN0)\n",
    "print(SYN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya tenemos definido las capas, las entradas y salida, comencemos con las iteraciones de la red neuronal.\n",
    "\n",
    "Lo primero es hacer el producto entre las entradas y las conexiones. Lo que da como resultado una qr activación, esto se mueve a la siguiente capa l2. Evaluando el error en esta capa final. Calculamos la diferencia con la derivada, esto debido a que nos devolvera valores que seviran de nuevos pesos para aprender en la siguiente iteración.\n",
    "\n",
    "Luego evaluamos las partes del error acumulado, para luego definir que valores ajustaremos en las conexiones de SYN1.\n",
    "\n",
    "Las 1ras conexiones se corrigen con `li_delta * entrada`, las 2das conexiones son corregidas con `l2_delta * entrada de la capra intermedia`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  0.009427862886120214\n",
      "Error:  0.00930639333702756\n",
      "Error:  0.009189443514526482\n",
      "Error:  0.009076740980230407\n",
      "Error:  0.00896803570153788\n",
      "Error:  0.008863097739553176\n",
      "Error:  0.00876171522185459\n",
      "Error:  0.008663692559567537\n",
      "Error:  0.008568848874712424\n",
      "Error:  0.00847701660915049\n",
      "Error:  0.00838804029086706\n",
      "Error:  0.008301775436997002\n",
      "Error:  0.008218087576043594\n",
      "Error:  0.008136851374289034\n",
      "Error:  0.00805794985353219\n",
      "Error:  0.007981273689087307\n",
      "Error:  0.00790672057849302\n",
      "Error:  0.007834194672671983\n",
      "Error:  0.007763606062372261\n",
      "Error:  0.007694870313654671\n",
      "[[0.01588941]\n",
      " [0.99040494]\n",
      " [0.9904041 ]\n",
      " [0.00263157]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20000):\n",
    "    layer0 = INPUT_X\n",
    "    # Multiplicamos las entradas con las conexiones\n",
    "    layer1 = sigmoid(np.dot(layer0, SYN0))\n",
    "    # En l1 tenemos los resultados de la primera activación, movemos esos datos a la capa siguiente\n",
    "    layer2 = sigmoid(np.dot(layer1, SYN1))\n",
    "    # Computamos el error de la capa final\n",
    "    layer2_error = EXPECTED_RESULT - layer2\n",
    " \n",
    "    # Computamos la diferencia con la derivada, dando el valor a añadir a los pesos para el aprendizaje\n",
    "    layer2_delta = layer2_error * sigmoid(layer2, True)\n",
    "    # El error acumulado, debido a las primeras conexiones\n",
    "    layer1_error = np.dot(layer2_delta, SYN1.T)\n",
    "    # Calculamos quw valor debemos ajustar, en las conexiones de SYN1\n",
    "    layer1_delta = layer1_error * sigmoid(layer1, True)\n",
    " \n",
    "    ## Corregimos las 1ras conexiones\n",
    "    SYN0 += np.dot(layer0.T, layer1_delta)\n",
    "    SYN1 += np.dot(layer1.T, layer2_delta)\n",
    "    if (i % 1000) == 0 :\n",
    "        print(\"Error: \", str(np.mean(np.abs(layer2_error))))\n",
    " \n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
